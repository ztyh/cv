\documentclass[utf8,letterpaper,oneside]{article}
% \documentclass[letterpaper,oneside]{ctexart}
% \usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}
%\usepackage{xeCJK}
%\usepackage{fontspec}
\usepackage{xcolor}
\usepackage{color,soul}
\usepackage{textcomp}
%\setmainfont{kaiu.ttf}
\graphicspath{ {images/}}
\usepackage[left=0.5in, right=0.5in, bottom=0.5in, top=0.5in]{geometry}
\newcommand*{\Skype}{\href{skype:john.smith?add}{john.smith}}
\newcommand{\Absender}[1][\normalsize]{\Skype}
\usepackage[symbol]{footmisc}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\pagenumbering{gobble}
\begin{document}
\noindent  \textit{\large\textbf{Zheye Yuan}}\footnote[1]{\noindent Dual citizenship. \textit{Tetsuya Hara} is on Japanese documents. \textit{Zheye Yuan} is on American documents.}
%\vspace{3ex}
%\hline
\small
\begin{center}
 \begin{tabular}{l l}
  Pennsylvania State University                  & \hspace{1in} \href{mailto:ztyh0121@gmail.com}{ztyh0121@gmail.com} or \href{mailto:zxy124@psu.edu}{zxy124@psu.edu} \\
  Department of Statistics                       & \hspace{1in}   \href{http://personal.psu.edu/zxy124/}{personal.psu.edu/zxy124}                                    \\
  325 Thomas Building, University Park, PA 16802 & \hspace{1in}+1 (814) 883-6639                                                                                     \\
 \end{tabular}
\end{center}
%\vspace{-3em}
\noindent
\begin{center}
 \begin{tabular}{l l}
  \hline
                           &                                                                                                               \\
  \textbf{Education}       & \textit{Pennsylvania State University, University Park}, \hl{Ph.D., Statistics}, expected May 2019,           \\
                           & Advisor: Bing Li, GPA: 3.96/4.00                                                                              \\
                           &                                                                                                               \\
                           & \textit{Hitotsubashi University, Kunitachi}, B.A., Economics, 2014,                                           \\
                           & Advisors: Naoyuki Ishimura, Kenta Kobayashi, GPA: 3.94/4.00                                                   \\
                           &                                                                                                               \\
                           & \textit{University of California, Berkeley}, Exchange, Mathematics, 2013                                      \\
                           & GPA: 3.814/4.00                                                                                               \\
                           &                                                                                                               \\ \hline
                           &                                                                                                               \\
  \textbf{Work \& Service} & \textit{\hl{Intern}, Research \& Development, Ford Global Data Insights \& Analytics}, Summer 2018            \\
  \textbf{Experience}      & Clustered car nameplates using hierarchical clustering and Poincar\'e embedding.                              \\
                           &                                                                                                               \\
                           & \textit{\hl{Intern}, Nomura Research Institute}, Summer 2013                                                  \\
                           & Analyzed interface \& data storage optimization for portable device used by insurance sales person.           \\
                           &                                                                                                               \\
                           & \textit{\hl{Consultant}, Statistical Consulting Center, Pennsylvania State University}, 2015                  \\
                           & Provided statistical consulting for graduate students from other departments.                                 \\
                           &                                                                                                               \\
                           & \textit{ASA Datafest \hl{Volunteer}}, Department of Statistics, Pennsylvania State University, 2017           \\
                           &                                                                                                               \\
                           & \textit{Dorm Management \hl{Volunteer}}, International Students Dormitory Association of Kodaira, 2012        \\
                           &                                                                                                               
  \\\hline
                           &                                                                                                               \\
  \textbf{Awards, }        & \hl{\textit{Best Poster Award}}, Penn State Statistics 50th Anniversary Conference, May 2018                  \\
  \textbf{Scholarships \&}
                           &                                                                                                               
  \textit{Graduate Assistanship}, Department of Statistics, Pennsylvania State University, 2014 to present                                 \\
  \textbf{Certification}   & \hl{Graded Ph.D. level} and \hl{taught Junior and Senior level} courses.                                      \\
  
                           & \hl{\textit{Excellent Academic Achievement}}, Department of Economics, Hitotsubashi University, 2012          \\
  
                           & \hl{\textit{Japan Student Services Organization Scholarship}}, for exchange to UC Berkeley, 2013              \\
                           & Actuarial Exam P, 11/17/2011, ID: 82124                                                                       \\
                           & Actuarial Exam FM, 4/9/2012, ID: 66205                                                                        \\
                           &                                                                                                               \\ \hline
                           &                                                                                                               \\
  \textbf{Research}        & \hl{Sufficient Dimension Reduction}, Functional Data Analysis, Support Vector Machines, \hl{Neural Networks}, \\
                           & Graph Embedding, Poincar\'e Embedding, \hl{Reproducing Kernel Hilber Space}                                   \\
                           &                                                                                                               \\ \hline
                           &                                                                                                               \\
  \textbf{Practical}       & Quantile Regression, Non-stationary Time Series Analysis,                                                     \\
  \textbf{Experiences}     & Discrete Cosine Transform Portfolio Construction, Linear \& Quadratic Programming,                            \\
                           & Numerical Calculation of Derivative Prices, Substitute Charge Method, Finite Element Method                   \\
                           &                                                                                                               \\ \hline
                           &                                                                                                               \\
  % \\
  \textbf{Notable}         & Statistical Computing, \hl{High Dimensional} Modelling \& Applications, \hl{Nonparametric} Methods            \\
  \textbf{Coursework}      & Stochastic Processes \& Monte Carlo Methods, Categorical Data, Regression Models, Theory of Statistics,       \\
                           & Asymptotic Tools, Probability Theory, Linear Models, Design and Analysis of Experiments                       \\
                           & Statistical Inference, Multivariate Analysis, Sufficient Dimension Reduction                                  \\
                           &                                                                                                               \\ \hline
                           &                                                                                                               \\
  \textbf{Languages}       & \hl{\texttt{python}} (used in internship and research)                                                        \\
                           & \hl{\texttt{julia}, \texttt{r}} (used in research)                                                            \\
                           & \hl{\texttt{c}, \texttt{c++}}, \texttt{matlab} (previously used in research)                                  \\
                           & \LaTeX, \texttt{html}, \texttt{css}, \hl{\texttt{git}}, experience with \texttt{UNIX} (used daily)            \\
                           & \hl{\texttt{sql}} (have some experience)                                                                      \\
                           & Japanese $>$ English $>$ Chinese $>$ French $>$ Spanish                                                       \\
 \end{tabular}
\end{center}
\newpage
\large
\subsubsection*{Elaboration on Coursework}
The listed courses are all Ph.D. level courses. This has involved many programming projects. I have also attended numerous seminars on Statistics. The Statistical instruction company Aidemy provides me with free access to their charged courses as well as their private courses. There, I have learned things such as reinforcement learning, image processing, data scraping, and natural language processing.
\subsubsection*{Elaboration on Teaching}
I have taught for four semesters. STAT 463 (a Junior and Senior level time series course), STAT 415 (Junior and Senior level statistical theory course), STAT 401 (twice, an easier version of STAT 415). For the last two semesters of teaching I have provided materials on my website. You may wish to take a look. You may wish to also take a look at my blog, the link of which is also provided on my website. On my blog, you may also see my \texttt{github} account. Although not all work is made public. I have also graded two Ph.D. level courses, STAT 513 and STAT 514 (theory of statistics I and II). These two cover the most important theoretical knowledge needed in the Ph.D. study of statistics.
\subsubsection*{Elaboration on Projects and Practical Experiences}
Because my undergraduate department had high interest in time series analysis, I had studied literatures on how to perform nonlinear modelling of quantiles in time series data in the early stages of graduate school. The core of the idea was to do separate regressions on a shifting window. For my undergraduate graduation project, I studied the repeating patterns of prices for stocks. Each stock has a coefficient for cosine functions of differnt frequencies. The idea was that the cosine function that only completes a half cycle corresponds to the trend. So we want to find a linear combination of the stocks that minimizes the coefficient on the trend while minimizing the coefficients of all other cosine components which corresponds to variance. This final part was done with Linear programming. During my undergraduate study, I extensively coded \texttt{c} implementations of numerical calculations of derivatives. Substitute charge method finds a solution that satisfies certain conditions by using basis functions that satisfy them. It is so called because for certain problems, these basis functions are exactly the ones that appear when you calculate the force by a charge in physics. Finite element method is another, more common way of calculating derivative prices. Also used in engineering, it approximates a continuous phenomenon by a discrete grid.
\subsubsection*{Elaboration on Research}
Currently I do MAVE (minimum average variance estimation) with neural networks. MAVE finds the dimension reducing matrix $W$ that minimizes the error in performing piecewise linear regression with $WX$. Neural networks can do nonlinear regression intrinsically. So we do not need to perform piecewise regression. In fact the matrix factor in the first affine transform in the neural network is exactly the $W$ we are looking for. We use this as well as variants of it to perform dimension reduction. Another project that I am currently doing is finding the standard error of a neural network estimator. This involves taking the second derivatives of the model. Due to the product rule, this derivation becomes much more complicated than the first derivative. Nonetheless it is something that can be done. Previously I had done support vector machine classifiers for multiple functional data using RKHS methods. This was unique in that it can handle multiple functions. It also gave superior results on real data on finding unhealthy patients from data on brain waves in multiple regions of the brain. I have also looked at combining global sufficient dimension reduction methods such as contour regression and directional regression with local dimension reduction methods such as MAVE. Other topics that I am doing include graph embedding, especially on non-traditional spaces. Graphs where vertices are functions can be embedded into traditional as well as non-traditional spaces. This has the benefit of not having to encode the edges, which increases in the order of $n \choose 2$. Embeddings has points of order $n$ instead. The similarity of pairs of points can be checked by the distance between them in the embedded space.
\end{document}
